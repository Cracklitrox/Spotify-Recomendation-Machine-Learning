{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a252909-fd82-4b46-803c-e8760e665232",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90fa55c-1dc9-460e-8e8a-66d89b6f4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge,ElasticNet,LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,accuracy_score,mean_squared_error, r2_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455b51f-faf1-4b1d-9263-0550f861e78e",
   "metadata": {},
   "source": [
    "### Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f971b7-9b0b-4b7d-9b95-63eac57b945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "directorio_actual = os.getcwd()\n",
    "\n",
    "# Specify the relative path from the current directory\n",
    "ruta_csv_relativa = os.path.join('..', 'data', '03_primary','3.spotify.csv')\n",
    "\n",
    "# Load the CSV file\n",
    "spotify = pd.read_csv(ruta_csv_relativa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e379f-b0ec-4b6c-bc0c-c7e04ce88f82",
   "metadata": {},
   "source": [
    "# Model of Regression (Diego)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a7c03-f674-4936-9c55-42847397418b",
   "metadata": {},
   "source": [
    "### The results indicate that Random Forest is the best model for predicting energy_scaled, with an R² of 0.778 meaning that around 78% of the variation in energy_scaled is explained by loudness_scaled and intensity.\n",
    "### The MSE and RMSE (both low) also indicate that the prediction error is low, meaning that the Random Forest model makes a good approximation to the actual values of energy_scaled.\n",
    "### This type of model can be very useful in any system that seeks to personalize, categorize or analyze music based on its loudness or energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b2223b-68b0-4b7a-955a-c172f414626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - energy_scaled prediction\n",
      "                        MSE        R²      RMSE\n",
      "Linear Regression  0.017176  0.725872  0.131056\n",
      "Decision Tree      0.014304  0.771707  0.119598\n",
      "Random Forest      0.013879  0.778491  0.117808\n"
     ]
    }
   ],
   "source": [
    "# Define function to evaluate models\n",
    "def train_and_evaluate(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(max_depth=5),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "    }\n",
    "\n",
    "    # Dictionary to store metrics for each model\n",
    "    metrics = {}\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Store metrics in dictionary\n",
    "        metrics[model_name] = {\n",
    "            \"MSE\": mse,\n",
    "            \"R²\": r2,\n",
    "            \"RMSE\": rmse\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(metrics).T\n",
    "\n",
    "# Model 1: energy_scaled ~ loudness_scaled + intensity\n",
    "X1 = spotify[['loudness_scaled', 'intensity']].values\n",
    "y1 = spotify['energy_scaled'].values\n",
    "results_model_1 = train_and_evaluate(X1, y1)\n",
    "print(\"Model 1 - energy_scaled prediction\")\n",
    "print(results_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b472f8-ec87-4676-ac71-05a9fd52037e",
   "metadata": {},
   "source": [
    "# Model of Regression (Diego)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe69235-f300-485b-b4cd-9d7dcdae4246",
   "metadata": {},
   "source": [
    "### The results indicate that Random Forest is the best performing model for predicting danceability_scaled with an R² of 0.314, meaning that the model explains only 31.4% of the variation in danceability_scaled. While this is better than the other models, it is still a relatively low value, suggesting that valence_scaled and energy_scaled are not sufficient to predict danceability with high accuracy.\n",
    "\n",
    "### The MSE and RMSE are also relatively low, indicating that the absolute error of the model is not high, but the low R² implies that there are other influential variables that are not being considered.\n",
    "\n",
    "### While this model offers some predictive power over danceability_scaled, the results suggest that valence_scaled and energy_scaled do not fully capture what makes a song “danceable.” Still, this model can be useful for preliminary song classification and improving music recommendations for users who prefer danceable songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c415d2-a015-4d2c-beb3-559d20950e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - danceability_scaled prediction\n",
      "                        MSE        R²      RMSE\n",
      "Linear Regression  0.026195  0.223513  0.161849\n",
      "Decision Tree      0.023377  0.307057  0.152894\n",
      "Random Forest      0.023128  0.314434  0.152078\n"
     ]
    }
   ],
   "source": [
    "# Model 2: danceability_scaled - valence_scaled + energy_scaled\n",
    "X2 = spotify[['valence_scaled', 'energy_scaled']].values\n",
    "y2 = spotify['danceability_scaled'].values\n",
    "results_model_2 = train_and_evaluate(X2, y2)\n",
    "print(\"Model 2 - danceability_scaled prediction\")\n",
    "print(results_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15b048-2043-4614-a8bd-479234f4b156",
   "metadata": {},
   "source": [
    "# Model of Regression (Diego)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac2346-be96-4d44-91d0-a76a4749a17f",
   "metadata": {},
   "source": [
    "### The results show a very low R² for all models (at best, Random Forest has an R² of 0.031), meaning that only 3.1% of the variation in popularity can be explained by intensity, valence_scaled, and energy_scaled. This indicates that these musical features are not sufficient to predict popularity, which makes sense, since popularity depends on many additional factors (promotion, release time, collaborations, etc.) that are not reflected in these variables.\n",
    "### The MSE and RMSE are also relatively high relative to the popularity scale, suggesting that the model has a considerable error in its predictions.\n",
    "\n",
    "### This model reveals that the popularity of a song cannot be predicted well by the musical features intensity, valence, and energy alone. Although these features may contribute to some extent, the popularity of a song seems to be influenced by other external factors that are not represented in this dataset.\n",
    "### Still, this model can be useful as a preliminary reference and to understand the complexity behind musical popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228657cb-dc79-4a9f-ad8b-b7d80cbcf25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - popularity_scaled prediction\n",
      "                        MSE        R²      RMSE\n",
      "Linear Regression  0.029694  0.001832  0.172319\n",
      "Decision Tree      0.029022  0.024405  0.170359\n",
      "Random Forest      0.028818  0.031285  0.169757\n"
     ]
    }
   ],
   "source": [
    "# Model 3: popularity_scaled - intensity + valence_scaled + energy_scaled\n",
    "X3 = spotify[['intensity', 'valence_scaled', 'energy_scaled']].values\n",
    "y3 = spotify['popularity_scaled'].values\n",
    "results_model_3 = train_and_evaluate(X3, y3)\n",
    "print(\"Model 3 - popularity_scaled prediction\")\n",
    "print(results_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab5d03-30db-47ad-81d2-059f95183846",
   "metadata": {},
   "source": [
    "# Model Of Classification (Diego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9044b2-ad3f-4947-bfcf-13a8ec972d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\OneDrive\\Imágenes\\Escritorio\\Spotify-Recomendation-Machine-Learning\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:18:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\diego\\OneDrive\\Imágenes\\Escritorio\\Spotify-Recomendation-Machine-Learning\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:18:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[8309 3621]\n",
      " [3154 7676]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71     11930\n",
      "           1       0.68      0.71      0.69     10830\n",
      "\n",
      "    accuracy                           0.70     22760\n",
      "   macro avg       0.70      0.70      0.70     22760\n",
      "weighted avg       0.70      0.70      0.70     22760\n",
      "\n",
      "Optimized Accuracy: 0.7023286467486819\n"
     ]
    }
   ],
   "source": [
    "# Feature selection for classification\n",
    "X_class_opt = spotify[['danceability_scaled', 'energy_scaled', 'acousticness_scaled', 'valence_scaled']]\n",
    "y_class_opt = spotify['popularity_class']  # Using popularity_class as the target variable\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_class_opt, y_class_opt, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameter configuration for random search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Creating the XGBoost model\n",
    "xgb_opt = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Configuring the random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_opt,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of hyperparameter combinations to try\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Running the random search to find the best parameters\n",
    "random_search.fit(X_train_opt, y_train_opt)\n",
    "\n",
    "# Training the best model found\n",
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X_train_opt, y_train_opt)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_opt = best_xgb.predict(X_test_opt)\n",
    "\n",
    "# Calculating the confusion matrix, classification report, and accuracy\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_opt, y_pred_opt))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_opt, y_pred_opt))\n",
    "accuracy_opt = accuracy_score(y_test_opt, y_pred_opt)\n",
    "print(\"Optimized Accuracy:\", accuracy_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7ec6c-0b3e-44e9-bce9-c3c634a340b4",
   "metadata": {},
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a9d3e-1e70-4361-b843-8b0d86509da9",
   "metadata": {},
   "source": [
    "# Model Of Classification (Diego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f06e08-a261-4653-976b-c864cd1cdfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7859 4071]\n",
      " [3962 6868]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66     11930\n",
      "           1       0.63      0.63      0.63     10830\n",
      "\n",
      "    accuracy                           0.65     22760\n",
      "   macro avg       0.65      0.65      0.65     22760\n",
      "weighted avg       0.65      0.65      0.65     22760\n",
      "\n",
      "Accuracy: 0.6470562390158172\n"
     ]
    }
   ],
   "source": [
    "# Feature selection for classification\n",
    "X_class = spotify[['danceability_scaled', 'energy_scaled', 'acousticness_scaled', 'valence_scaled']]\n",
    "y_class = spotify['popularity_class']  # Using popularity_class instead of explicit\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the KNN model for classification\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Training the model\n",
    "knn.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_knn = knn.predict(X_test_class)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_class, y_pred_knn)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Generating the classification report\n",
    "report = classification_report(y_test_class, y_pred_knn)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculating accuracy\n",
    "accuracy_knn = accuracy_score(y_test_class, y_pred_knn)\n",
    "print(\"Accuracy:\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023931d4-acf9-4e9c-baa6-d96da12926ec",
   "metadata": {},
   "source": [
    "# Model Of Classification (Diego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be6f55-6956-45de-b18c-1d86868b1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection for classification\n",
    "X_class_rf = spotify[['danceability_scaled', 'energy_scaled', 'acousticness_scaled', 'valence_scaled']]\n",
    "y_class_rf = spotify['popularity_class']  # Using popularity_class instead of explicit\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_class_rf, y_class_rf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the Random Forest model for classification\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_rf = rf.predict(X_test_rf)\n",
    "\n",
    "# Calculating the confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_rf, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_rf, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_rf, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
